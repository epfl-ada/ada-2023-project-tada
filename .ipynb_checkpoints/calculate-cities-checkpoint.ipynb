{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m     15\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/tanguydeclety/Documents/GitHub/ada-2023-project-tada/data/tada/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "from helpers import load_data, get_embedding\n",
    "import plotly.graph_objects as go\n",
    "import threading\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_PATH = '/Users/tanguydeclety/Documents/GitHub/ada-2023-project-tada/data/tada/'\n",
    "\n",
    "# Load the data\n",
    "loaded_data = load_data(DATA_PATH)\n",
    "\n",
    "character_metadata = loaded_data['character_metadata']\n",
    "movie_metadata = loaded_data['movie_metadata']\n",
    "plot_summaries = loaded_data['plot_summaries']\n",
    "embeddings = loaded_data['embeddings']\n",
    "combined_plot_summaries = loaded_data['combined_plot_summaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load from movie_analysis.json and convert to df\n",
    "with open('movie_analysis.json', 'r') as f:\n",
    "    answers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "\n",
    "         You will give some extra information about a movie given its summary.\n",
    "         You will give a json string that will contain the following:\n",
    "         - Cities and towns where the action takes place include every city. If there are no cities, give an empty list/\n",
    "         - Countries where the action takes place. If there is no country, give an empty list.\n",
    "         - Make a dictionary of main characters and give for each: nationality(if present), if the character is evil, neutral or good.\n",
    "        \n",
    "         If the cities/ countries are fictional and thus not real you should not include them at all. Same for nationalities.\n",
    "         So for example you should not include Hogwarts as a city, or Middle Earth as a country or Panem as a country.\n",
    "         \n",
    "         Nationationalities should also only be the country.\n",
    "         Example:\n",
    "\n",
    "         Movie Description:\n",
    "         \"In 'The Heist', a skilled team of thieves plan a daring bank robbery in downtown Los Angeles. The plot thickens when they realize they are being pursued by an FBI agent determined to bring them to justice. The story is a thrilling cat-and-mouse game set against the backdrop of the bustling city.\" \n",
    "         {\n",
    "            \"cities\": [\n",
    "               \"Los Angeles\"\n",
    "            ],\n",
    "            \"countries\": [\n",
    "                \"USA\"\n",
    "            ],\n",
    "            \"characters\": {\n",
    "                \"John\": {\n",
    "                    \"nationality\": \"USA\",\n",
    "                    \"alignment\": \"evil\"\n",
    "                },\n",
    "                \"Agent Smith\": {\n",
    "                    \"nationality\": \"USA\",\n",
    "                    \"alignment\": \"neutral\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str = 'cl100k_base') -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()\n",
    "processed_count = 0\n",
    "input_token_count = 0\n",
    "output_token_count = 0\n",
    "MAX_THREADS = 10\n",
    "SAVE_INTERVAL = 100\n",
    "LARGE_SAVE_INTERVAL = 500\n",
    "PRINT_INTERVAL = 50\n",
    "\n",
    "def process_movie(wiki_id, movie):\n",
    "    global processed_count, input_token_count, output_token_count,answers, lock\n",
    "    times = 0\n",
    "    while times < 3:\n",
    "        try:\n",
    "            with lock:\n",
    "                if wiki_id in answers or str(wiki_id) in answers or int(wiki_id) in answers:\n",
    "                    print(\"Movie already processed \", wiki_id)\n",
    "                    return\n",
    "\n",
    "            input_tokens = num_tokens_from_string(f\"Analyze this movie: {movie}\") + num_tokens_from_string(system_prompt)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo-1106\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Analyze this movie: {movie}\"}\n",
    "                ],\n",
    "                seed=42,\n",
    "            )\n",
    "\n",
    "            output_tokens = num_tokens_from_string(response.choices[0].message.content)\n",
    "\n",
    "            with lock:\n",
    "                answers[wiki_id] = response.choices[0].message.content\n",
    "                processed_count += 1\n",
    "                input_token_count += input_tokens\n",
    "                output_token_count += output_tokens\n",
    "\n",
    "                if processed_count % SAVE_INTERVAL == 0:\n",
    "                    print(\"Saving progress...\")\n",
    "                    save_to_file()\n",
    "                if processed_count % LARGE_SAVE_INTERVAL == 0:\n",
    "                    print(\"Saving large progress...\")\n",
    "                    save_to_file(f\"movie_analysis_{processed_count}.json\")\n",
    "                if processed_count % PRINT_INTERVAL == 0:\n",
    "                    print_cost()\n",
    "\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(\"Rate limit hit, waiting for 45 seconds...\")\n",
    "            time.sleep(45)\n",
    "            times += 1\n",
    "\n",
    "    if times == 3:\n",
    "        print(\"Movie skipped \", wiki_id)\n",
    "    else:\n",
    "        print(\"Movie processed \", wiki_id)\n",
    "\n",
    "def print_cost():\n",
    "    input_cost = (input_token_count / 1000) * 0.001\n",
    "    output_cost = (output_token_count / 1000) * 0.002\n",
    "    total_cost = input_cost + output_cost\n",
    "    print(f\"Processed {processed_count} movies. Total cost so far: ${total_cost:.2f}\")\n",
    "    print(f\"Input tokens: {input_token_count}, Output tokens: {output_token_count}\")\n",
    "\n",
    "def save_to_file(filename='movie_analysis.json'):\n",
    "    global answers\n",
    "    with open(filename, 'w') as file:\n",
    "        file.seek(0)\n",
    "        json.dump(answers, file)\n",
    "\n",
    "def process_batch(start_index, batch_size):\n",
    "    for i in range(start_index, start_index + batch_size):\n",
    "        if i < len(combined_plot_summaries):\n",
    "            wiki_id = combined_plot_summaries['Wikipedia movie ID'].values[i]\n",
    "            movie = combined_plot_summaries['Summary'].values[i]\n",
    "            process_movie(wiki_id, movie)\n",
    "\n",
    "threads = []\n",
    "num_movies = len(combined_plot_summaries)\n",
    "batch_size = num_movies // MAX_THREADS\n",
    "\n",
    "for i in range(0, num_movies, batch_size):\n",
    "    thread = threading.Thread(target=process_batch, args=(i, batch_size))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in tqdm(threads):\n",
    "    thread.join()\n",
    "\n",
    "print(\"All movies processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file(\"movie_analysis_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
