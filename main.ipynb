{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does cinema view the world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will explore how cities and countries are depicted in cinema.\n",
    "\n",
    "We will explore this topic from multiple aspects.\n",
    "\n",
    "Contents:\n",
    "\n",
    "0. [Data preprocessing](#data-preprocessing)\n",
    "1. [General analysis by city/country](#general-analysis-by-location)\n",
    "2. [Genre distributions & Bias](#genre-distributions--bias)\n",
    "3. [Exploring how different countries view each other](#exploring-how-different-countries-view-each-other)\n",
    "4. [Exploring how locations changed their view in time](#exploring-how-locations-changed-their-view-in-time)\n",
    "5. [Character depiction and stereotypes](#character-depiction-and-stereotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the required libraries and helper functions we will need for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We use google maps to get the coordinates of the cities/countries.\n",
    "import googlemaps\n",
    "\n",
    "# We use our own helper functions to load the data and get an embedding.\n",
    "from helpers import load_data, get_embedding\n",
    "\n",
    "# To track progress we use the tqdm package.\n",
    "import tqdm\n",
    "\n",
    "# To load our generated movie analysis we will use the json package.\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# We hide warnings to make the notebook a bit cleaner.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "For the project we are using the [CMU Movie Summary Corpus](https://www.cs.cmu.edu/~ark/personas/) which contains plot summaries of 42,306 movies. The dataset also contains a number of metadata information about the movie and the actors.\n",
    "\n",
    "We will use the following files from the dataset:\n",
    "- `plot_summaries.txt` - which contains the plot summaries.\n",
    "- `character.metadata.tsv` - which contains information about the characters and actors that play in a movie.\n",
    "- `movie.metadata.tsv` - which contains information about movies.\n",
    "\n",
    "\n",
    "As our project explores how *cinema views the world* as our main tool we have decided to analyze how the location of a movie affects the story, characters and what bias can be found.\n",
    "\n",
    "#### Location information\n",
    "The dataset does not provide the plot location to us and as such we have extracted location information using the newly released [JSON ChatGPT API](https://platform.openai.com/docs/guides/text-generation/json-mode).\n",
    "\n",
    "With the use of the OpenAI API we have extracted the following information for each movie summary:\n",
    "\n",
    "Example output of the movie ***Pest from the West***\n",
    "```json\n",
    "{\n",
    "   \"cities\": [\n",
    "      \"Mexico City\"\n",
    "   ],\n",
    "   \"countries\": [\n",
    "      \"Mexico\"\n",
    "   ],\n",
    "   \"characters\": {\n",
    "      \"Keaton\": {\n",
    "         \"nationality\": \"USA\",\n",
    "         \"alignment\": \"good\"\n",
    "      }\n",
    "   }\n",
    "}\n",
    "```\n",
    "\n",
    "This data resides in the `movie_analysis.json` file. The code that helped us generate these results resides in `calculate-locations.ipynb`.\n",
    "\n",
    "#### Embeddings\n",
    "We have also computed semantic embeddings of all summaries in order to be able to get similarity metrics between movies or from a term to a movie. To calculate these embeddings we have used the [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings). Each embedding vector is `1536` dimensional.\n",
    "\n",
    "The embeddings are stored in the `embeddings.npy` file. The code that helped us generate these results resides in `calculate-embeddings.ipynb`.\n",
    "\n",
    "\n",
    "#### TMDB Dataset\n",
    "\n",
    "We plan on using the [TMDB databaset](https://www.themoviedb.org) in order to get good user scores for movies. This dataset provides us with an easy to use python library and as such there will be no data problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "\n",
    "# We load the data using our helper function.\n",
    "loaded_data = load_data(DATA_PATH)\n",
    "\n",
    "# We initialize the google maps client using our API key.\n",
    "gmaps = googlemaps.Client(key=os.environ['GOOGLE_MAPS_API_KEY'])\n",
    "\n",
    "# We extract the variables from the loaded data.\n",
    "character_metadata = loaded_data['character_metadata'] # The metadata of the characters.\n",
    "movie_metadata = loaded_data['movie_metadata'] # The metadata of the movies.\n",
    "plot_summaries = loaded_data['plot_summaries'] # The plot summaries of the movies.\n",
    "embeddings = loaded_data['embeddings'] # The embeddings of the movies as a numpy array.\n",
    "combined_plot_summaries = loaded_data['combined_plot_summaries'] # The movie summaries combined with their embeddings.\n",
    "city_country_analysis = loaded_data['city_country_analysis'] # The analysis of the cities and countries.\n",
    "cities = city_country_analysis['cities'] # A list of all the cities.\n",
    "countries = city_country_analysis['countries'] # A list of all the countries.\n",
    "cities_movies = city_country_analysis['cities_movies'] # A dictionary mapping cities to movies.\n",
    "countries_movies = city_country_analysis['countries_movies'] # A dictionary mapping countries to movies.\n",
    "embeddings_of_movies_in_cities = city_country_analysis['embeddings_of_movies_in_cities'] # A dictionary mapping cities to embeddings of movies.\n",
    "embeddings_of_movies_in_countries = city_country_analysis['embeddings_of_movies_in_countries'] # A dictionary mapping countries to embeddings of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General analysis by location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre distributions & Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring how different countries view each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring how locations changed their view in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character depiction and stereotypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
